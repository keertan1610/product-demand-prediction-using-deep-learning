{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zyOdAjEiXAL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/amankharwal/Website-data/master/demand.csv\")\n",
        "\n",
        "print(data.head())\n",
        "print(data.info())\n",
        "print(data.describe())\n",
        "\n",
        "data = data.drop(columns=['ID'])\n",
        "\n",
        "print(data.isnull().sum())\n",
        "\n",
        "data = data.dropna()\n",
        "\n",
        "X = data[['Store ID', 'Total Price', 'Base Price']]\n",
        "y = data['Units Sold']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, input_dim=3, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error')\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train_scaled, y_train, validation_split=0.2, epochs=25, batch_size=10, callbacks=[early_stopping])\n",
        "\n",
        "loss = model.evaluate(X_test_scaled, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    return mse, mae, r2\n",
        "\n",
        "\n",
        "mse, mae, r2 = evaluate_model(y_test, y_pred)\n",
        "print(f\"Deep Learning Model - MSE: {mse}, MAE: {mae}, R2: {r2}\")\n",
        "\n",
        "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred.flatten()})\n",
        "\n",
        "\n",
        "sns.scatterplot(x='Actual', y='Predicted', data=df)\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Neural Network Predictions')\n",
        "plt.show()\n"
      ]
    }
  ]
}